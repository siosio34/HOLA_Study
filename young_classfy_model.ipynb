{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "read_data = pd.read_csv(\"shopping-ca-cls.data.tsv\", \n",
    "                        encoding=\"utf-8\", names=['shoes_species', 'maker_name', 'brand_name', 'price','image_url','name'],\n",
    "                        sep='\\t')\n",
    "# test data 읽어오기.\n",
    "\n",
    "read_test_data = pd.read_csv(\"shopping-ca-cls.data.test.tsv\", \n",
    "                        encoding=\"utf-8\", names=['shoes_species', 'maker_name', 'brand_name', 'price','image_url','name'],\n",
    "                        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "\n",
    "def nlp_with_konolpy_twitter_class():\n",
    "    print('konolpy load complete')\n",
    "\n",
    "\n",
    "# 특수 문자제거 , 자연어 처리\n",
    "def process_character(name):\n",
    "    # 특수 문자제거\n",
    "    new_name = re.sub(\"[\\,\\.\\%\\-\\_\\/]\",' ',name)\n",
    "    #new_name = re.sub(\"[^\\D]\",' ', new_name)\n",
    "    #new_name = re.sub(\"[\\d]\",' ', new_name)\n",
    "    new_name = new_name.strip()\n",
    "    \n",
    "    # 자연어 처리\n",
    "    nouns_str = twitter.morphs(new_name)\n",
    "    make_new_str = ''\n",
    "    for r in nouns_str:\n",
    "        make_new_str =  make_new_str + r + ' '\n",
    "    \n",
    "    #print(make_new_str)   \n",
    "    #twitter.nouns\n",
    "    #print(new_name)\n",
    "    return make_new_str\n",
    "    \n",
    "    \n",
    "def test_from_input_product_name():\n",
    "    while (1) :\n",
    "        input_product_name = input()\n",
    "        pred = clf.predict(vectorizer.transform([input_product_name]))[0]\n",
    "        print(\"예상되는 상품태그는 : \" , list(category_dict.keys())[list(category_dict.values()).index(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todo 새로운 상품 이름 만든다음에 단어추가!\n",
    "shoes_category_list = []\n",
    "new_shoes_name_for_vectornizer_list = []\n",
    "count = 0\n",
    "for each_row in read_data.iterrows():\n",
    "    #print(each_row[1]['name'])\n",
    "    processed_name = process_character(each_row[1]['name'])\n",
    "    #print(each_row[1]['maker_name'])\n",
    "    #print(each_row[1]['brand_name'])\n",
    "    if pd.isnull(each_row[1]['maker_name']) == False :\n",
    "        processed_name = processed_name + each_row[1]['maker_name'] + ' '\n",
    "    if pd.isnull(each_row[1]['brand_name']) == False :\n",
    "        processed_name = processed_name + each_row[1]['brand_name']\n",
    "    \n",
    "    new_shoes_name_for_vectornizer_list.append(processed_name)\n",
    "    shoes_category_list.append(each_row[1]['shoes_species'])\n",
    "    #new_shoes_name_for_vectornizer_list.append(each_row[1]['name'])\n",
    "    \n",
    "    \n",
    "vectorizer = CountVectorizer()\n",
    "x_list = vectorizer.fit_transform(new_shoes_name_for_vectornizer_list)\n",
    "#print(x_list)\n",
    "\n",
    "y_list = []\n",
    "category_dict = dict(zip(list(set(shoes_category_list)),range(len(set(shoes_category_list)))))\n",
    "\n",
    "print(category_dict)\n",
    "for each in read_data.iterrows():\n",
    "    y_list.append(category_dict[each[1]['shoes_species']])\n",
    "    \n",
    "#print(len(set(shoes_category_list)))\n",
    "#print(category_dict[u'기능화']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "svc_param = {'C':np.logspace(-2,0,20)}\n",
    "grid_search_cv = GridSearchCV(svm.LinearSVC(),param_grid,cv=5,n_jobs=4)\n",
    "grid_search_cv.fit(x_list,y_list)\n",
    "print(grid_search_cv.best_params_, grid_search_cv.best_score_)\n",
    "\n",
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                     'C': [1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "#\n",
    "\n",
    "#Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#gammas = [0.001, 0.01, 0.1, 1]\n",
    "#param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "# tuned_parameters = {'C':np.logspace(-2,0,20)}\n",
    "# \n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                     'C': [1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "#clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring=score)\n",
    "#\n",
    "#grid_search_cv2 = GridSearchCV(svm.SVC(),param_grid,cv=5,n_jobs=4)\n",
    "3\n",
    "#grid_search_cv.fit(x_list,y_list)\n",
    "#grid_search_cv2.fit(x_list,y_list)\n",
    "\n",
    "#print(grid_search_cv.best_params_, grid_search_cv.best_score_);\n",
    "#print(grid_search_cv2.best_params_, grid_search_cv2.best_score_);\n",
    "\n",
    "#from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(C=grid_search_cv.best_params_['C'])\n",
    "clf.fit(x_list,y_list)\n",
    "\n",
    "count_num = 0\n",
    "yes_num = 0\n",
    "\n",
    "pred = clf.predict(vectorizer.transform(['안전화_WK504NR_265mm_|조| 안전화 작업화 경량안전화 소방 안전용품']))[0]\n",
    "print(pred);\n",
    "print(y_list[0])\n",
    "\n",
    "#print(list(category_dict.keys())[list(category_dict.values()).index(pred)]);\n",
    "\n",
    "for each_row in read_data.iterrows():\n",
    "   # predict_x = vectorizer.transform(each_row[1]['name'])\n",
    "    #print(clf.predict(vectorizer.transform([each_row[1]['name']]))[0])\n",
    "    #print(y_list[count_num])\n",
    "    processed_name = process_character(each_row[1]['name'])\n",
    "    \n",
    "    if pd.isnull(each_row[1]['maker_name']) == False :\n",
    "        processed_name = processed_name + each_row[1]['maker_name'] + ' '\n",
    "    if pd.isnull(each_row[1]['brand_name']) == False :\n",
    "        processed_name = processed_name + each_row[1]['brand_name']\n",
    "        \n",
    "    if clf.predict(vectorizer.transform([processed_name]))[0] == y_list[count_num] :\n",
    "        yes_num = yes_num + 1\n",
    "        \n",
    "    count_num = count_num + 1\n",
    "    \n",
    "print('Accuracy Score : ', yes_num / count_num)\n",
    "\n",
    "#print(count_num)\n",
    "#print(yes_num)\n",
    "#print(\"yes : %f\", yes_num / count );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 상품 이름만 처리 하였을때 -> 원본 데이터와 일치율 정답율 : 0.9720026835534175 테스트 데이터로 모델테스트 61%\n",
    "# 상품 이름 + 특수 문자제거 -> 원본 데이터와 일치율 0.9140117487277666 테스트 데이터로 모델테스트 ,0.6118598382749326 \\\n",
    "# 상품 이름 + 특수문자제거 + NLP 처리. -> 원본 데이터와 일치율 0.67 테스트 데이터로 모델테스트 66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_list2 = []\n",
    "yes_num2 = 0\n",
    "count_num2 = 0\n",
    "\n",
    "for each in read_test_data.iterrows():\n",
    "    shoes_species_dict = category_dict[each[1]['shoes_species']] \n",
    "    \n",
    "    #original_dict = clf.predict(vectorizer.transform([each[1]['name']]))[0]\n",
    "    #print(shoes_species_dict,original_dict)\n",
    "    processed_test_data_name = process_character(each[1]['name'])\n",
    "    if pd.isnull(each[1]['maker_name']) == False :\n",
    "        processed_test_data_name = processed_test_data_name + each[1]['maker_name'] + ' '\n",
    "    if pd.isnull(each[1]['brand_name']) == False :\n",
    "        processed_test_data_name = processed_test_data_name + each[1]['brand_name']\n",
    "        \n",
    "    if clf.predict(vectorizer.transform([processed_test_data_name]))[0] == shoes_species_dict :\n",
    "        yes_num2 = yes_num2 + 1\n",
    "        \n",
    "    count_num2 = count_num2 + 1\n",
    "    \n",
    "#print(yes_num2, count_num2)    \n",
    "print('Accuracy Score : ', yes_num2 / count_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}